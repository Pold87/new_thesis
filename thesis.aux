\relax 
\abx@aux@sortscheme{nty}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{english}}
\abx@aux@cite{grzonka2009towards}
\abx@aux@cite{bachrach2009autonomous}
\abx@aux@cite{blosch2010vision}
\abx@aux@cite{angeli20062d}
\abx@aux@cite{ahrens2009vision}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:introduction}{{1}{3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces { The figure illustrates the developed system from a high-level perspective. A feature vector---the texton histogram---is extracted from the current camera image of the UAV. The feature vector is forwarded to a machine learning model that uses a $k$-Nearest Neighbors algorithm to output $x,y$-position estimates. These estimates are passed to a particle filter, which filters position estimates over time and outputs a final position estimate (red point). The expected loss shows regions in the map where a lower localization accuracy is expected. The average expected loss can be used as ``fitness value'' of a given map.}\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:highleveloverview}{{1.1}{4}}
\abx@aux@cite{varma2005statistical}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem Statement and Research Questions}{5}}
\newlabel{sec:researchquestions}{{1.1}{5}}
\abx@aux@cite{brisset2006paparazzi}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contributions}{6}}
\newlabel{sec:contributions}{{1.2}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis Outline}{7}}
\newlabel{sec:outline}{{1.3}{7}}
\abx@aux@cite{fox1999monte}
\abx@aux@cite{engelson1992error}
\abx@aux@cite{kato1999marker}
\abx@aux@cite{garrido2014automatic}
\abx@aux@cite{eberli2011vision}
\abx@aux@cite{bebop2015}
\abx@aux@cite{aruco2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:relatedwork}{{2}{8}}
\abx@aux@cite{hornecker2005using}
\abx@aux@cite{albasiouny2015mean}
\abx@aux@cite{chu2013halftone}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Vision-based Localization Methods}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Fiducial Markers}{9}}
\newlabel{sec:fiducialmarkers}{{2.1.1}{9}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces { Examples of fiducial markers of the ArUco library.}\relax }}{9}}
\newlabel{fig:aruco}{{2.1}{9}}
\abx@aux@cite{se2002global}
\abx@aux@cite{lowe1999object}
\abx@aux@cite{kendall2015posenet}
\abx@aux@cite{achtelik2011onboard}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Homography Determination \& Keypoint Matching}{10}}
\newlabel{sec:keypointmatching}{{2.1.2}{10}}
\abx@aux@cite{lecun1998gradient}
\abx@aux@cite{dosovitskiy2014discriminative}
\abx@aux@cite{collobert2011torch7}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces {Perspective transformation between keypoints of the current image (left) and the reference or map image (right).}\relax }}{11}}
\newlabel{fig:sift}{{2.2}{11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Convolutional Neural Networks}{11}}
\abx@aux@cite{ruffier2003bio}
\abx@aux@cite{chao2013survey}
\abx@aux@cite{mcguire2016local}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Optical Flow}{12}}
\newlabel{sec:opticalflow}{{2.1.4}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Texton-based Methods}{12}}
\newlabel{sec:textonbasedapproaches}{{2.2}{12}}
\abx@aux@cite{de2009design}
\abx@aux@cite{de2012appearance}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods}{14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methods}{{3}{14}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces High-level texton framework\relax }}{14}}
\newlabel{alg:trexton_run}{{1}{14}}
\abx@aux@cite{bebop}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Hardware and Software}{15}}
\newlabel{sec:hardware}{{3.1}{15}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces { Comparison of an unmodified Parrot AR.Drone.2.0 (left) and a modified version (right). The modified one was equipped with an Odroid XU-4 single board computer, a Logitech C525 HD camera, a WiFi module, and a USB connection between the Odroid board and the AR.Drone.2.0 flight controller.}\relax }}{15}}
\newlabel{fig:comparison}{{3.1}{15}}
\abx@aux@cite{paparazzi}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces { The ground control station of the Paparazzi software. It displays information about the status of the UAV and provides functions for controlling the vehicle (from PaparazziUAV wiki \cite {paparazzi}).}\relax }}{17}}
\newlabel{fig:gcs}{{3.2}{17}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Preliminary Dataset Generation}{17}}
\newlabel{sec:mapping}{{3.2}{17}}
\abx@aux@cite{ice}
\abx@aux@cite{hugin}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces {Training dataset generation if the motion tracking system is used. The texton histograms of the camera images during flight are extracted and aligned with the highly accurate position estimates of the motion tracking system. The result is a high-quality training set of texton histograms and corresponding $x,y$-positions.}\relax }}{18}}
\newlabel{fig:overviewn}{{3.3}{18}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces { The figure illustrates the training set generation when applying the homography-based approach. Images from an initial flight are stitched together to create an orthomap. The same images are used to detect and describe their keypoints using \textsc  {Sift}, followed by finding a homography between the keypoints of the flight images and the orthomap to obtain $x, y$-coordinates per image. The training set is created by extracting texton histograms from the images. }\relax }}{20}}
\newlabel{fig:overview_sift}{{3.4}{20}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Machine Learning-based Approach and Filtering}{20}}
\newlabel{sec:textons}{{3.3}{20}}
\abx@aux@cite{varma2003texture}
\abx@aux@cite{kohonen1990self}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces { This figure shows the created orthomap of a texture-rich floor. It is stitched together using 100 single images and represents a real world area of approximately $8\times 8$ meters. Image distortions, non-mapped areas, and slightly skewed seams at several points are visible.}\relax }}{21}}
\newlabel{fig:orthomap}{{3.5}{21}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Texton Dictionary Generation}{21}}
\newlabel{sec:text-dict-gener}{{3.3.1}{21}}
\abx@aux@cite{guyon2006introduction}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces { The figures shows a dictionary consisting of 20 grayscale textons ($w \times h = 6 \times 6$ pixels).}\relax }}{22}}
\newlabel{fig:dictionary}{{3.6}{22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Histogram Extraction}{22}}
\newlabel{sec:histogramextract}{{3.3.2}{22}}
\abx@aux@cite{de2012sub}
\abx@aux@cite{kordos2010we}
\abx@aux@cite{knn}
\abx@aux@cite{bhatia2010survey}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}$k$-Nearest Neighbors ($k$-NN) algorithm}{23}}
\newlabel{sec:knn}{{3.3.3}{23}}
\abx@aux@cite{dellaert1999monte}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Filtering}{24}}
\newlabel{sec:filtering}{{3.3.4}{24}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Kalman Filter.}}{25}}
\newlabel{fig:kali}{{3.7}{25}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Bayesian Filter.}}{26}}
\newlabel{fig:bayes}{{3.8}{26}}
\abx@aux@cite{thrun}
\abx@aux@cite{driessen2008map}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Particle filter update\relax }}{27}}
\newlabel{alg:particle_filter}{{2}{27}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Resampling wheel\relax }}{28}}
\newlabel{alg:resampling_wheel}{{3}{28}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Map evaluation}{29}}
\newlabel{sec:mapeval}{{3.4}{29}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Evaluation Scheme}{29}}
\newlabel{sec:evaluationscheme}{{3.4.1}{29}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces {\emph  {Left:} Actual similarity between histogram $h_i$ ($\text  {pos}_i$: white cross) and all other histograms; the heatmap shows low similarity in blue and high similarity in red. For the visualization, the actual similarities were smoothed with a Gaussian filter. \emph  {Middle:} Ideal histogram similarity distribution for the given position $\text  {pos}_i$. Histograms $h_j$ taken at closeby positions should have a high similarity to $h_i$. The farther away the position $\text  {pos}_j$, the lower the similarity between $h_i$ and $h_j$ should be. \emph  {Right:} The difference between the actual and the ideal similarity shows regions that do not follow the ideal similarity distribution for histogram $h_i$ (high loss: red; low loss: blue)}\relax }}{30}}
\newlabel{fig:local_loss}{{3.9}{30}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces The figure shows the loss of a map: the regions that did not follow the ideal similarity pattern are displayed in red. For the visualization, the loss values per sample in the dataset were smoothed with a Gaussian filter. This assigns a loss value to each $x,y$-position of the map. The synthetic data generation tool was used for generating the underlying dataset (Section~\ref  {sec:syntheticdatageneration}). \relax }}{31}}
\newlabel{fig:globalloss}{{3.10}{31}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Synthetic Data Generation}{31}}
\newlabel{sec:syntheticdatageneration}{{3.4.2}{31}}
\abx@aux@cite{jepson}
\abx@aux@cite{hartley2003multiple}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces { Six image patches generated by means of the synthetic data generation tool.}\relax }}{32}}
\newlabel{fig:montage}{{3.11}{32}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces { Illustration of the camera model for the synthetic flight. The developed tool extracts image patches from an given image to simulate those taken with the bottom camera of the MAV during an actual flight.}\relax }}{32}}
\newlabel{fig:cammodel}{{3.12}{32}}
\abx@aux@cite{opti}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Analysis}{36}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:analysis}{{4}{36}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Determining the Number of Image Patches}{36}}
\newlabel{sec:numtextons}{{4.1}{36}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The indoor flight arena at the Delft University of Technology \relax }}{37}}
\newlabel{fig:cyberzoo}{{4.1}{37}}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{\color@box {}{red!25}{\leavevmode {\color  {red!25}o}}\ add standard deviation}{37}}
\pgfsyspdfmark {pgfid1}{8275230}{17669700}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{\color@box {}{red!25}{\leavevmode {\color  {red!25}o}}\ add accuracy and not only similarity}{37}}
\pgfsyspdfmark {pgfid6}{8275230}{17669700}
\pgfsyspdfmark {pgfid4}{34440477}{17685147}
\pgfsyspdfmark {pgfid5}{36357404}{17437973}
\pgfsyspdfmark {pgfid9}{34440477}{16091537}
\pgfsyspdfmark {pgfid10}{36357404}{15844363}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Determining $k$ in the $k$-NN algorithm}{37}}
\newlabel{sec:detk}{{4.2}{37}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces { Cosine similarity of histograms as a function of the number of extracted samples \emph  {Right}: Standard deviation of cosine similarity in relation to the number of samples. The squares indicate the positions at which the dependency was evaluated.}\relax }}{38}}
\newlabel{fig:cosine}{{4.2}{38}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}Measurement model for the Particle Filter}{38}}
\newlabel{sec:measurementmodel}{{4.3}{38}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Correlation between histogram distance and Measurement Error}{38}}
\newlabel{fig:measurementmodel}{{\caption@xref {fig:measurementmodel}{ on input line 1773}}{39}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces {Variance and dependence between error in $x$-direction (\emph  {Left}) and $y$-direction (\emph  {Left}).}\relax }}{39}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.5}Correlation between number of keypoints and Quality of the Homography}{39}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.6}Continuous Coordinate Estimation}{39}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Training Set based on Motion Tracking System}{39}}
\newlabel{sec:experiment-real}{{4.6.1}{39}}
\newlabel{fig:cosinesim}{{\caption@xref {fig:cosinesim}{ on input line 1793}}{40}}
\newlabel{sub@fig:cosinesim}{{}{40}}
\newlabel{fig:cosinesd}{{\caption@xref {fig:cosinesd}{ on input line 1799}}{40}}
\newlabel{sub@fig:cosinesd}{{}{40}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Measurement error in $x$-direction (\emph  {Left}) and $y$-direction (\emph  {Right}) as a function of the distance to the closest training sample.\relax }}{40}}
\newlabel{fig:cor_sim_confi}{{4.4}{40}}
\newlabel{fig:cor_keypoints}{{\caption@xref {fig:cor_keypoints}{ on input line 1814}}{40}}
\newlabel{fig:cosinesim}{{\caption@xref {fig:cosinesim}{ on input line 1819}}{40}}
\newlabel{sub@fig:cosinesim}{{}{40}}
\newlabel{fig:cosinesd}{{\caption@xref {fig:cosinesd}{ on input line 1825}}{40}}
\newlabel{sub@fig:cosinesd}{{}{40}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Measurement error in $x$-direction (\emph  {Left}) and $y$-direction (\emph  {Right}) as a function of the number of keypoints found by \textsc  {Sift}.\relax }}{40}}
\newlabel{fig:cosine}{{4.5}{40}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Estimates of the texton-based approach}}{41}}
\newlabel{tab:route}{{4.1}{41}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces { The estimates of the homography method compared to the ground truth of the motion tracking system. TODO: Legend}\relax }}{41}}
\newlabel{fig:flightpath}{{4.6}{41}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Error statistics homography method.}}{42}}
\newlabel{tab:homoerror}{{4.2}{42}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Training Set based on Homography-finding Method}{42}}
\newlabel{sec:traininghomo}{{4.6.2}{42}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces { The created map that was stitched together using 445 images. A non-mapped area in the middle of the map can be seen, which is a result of the set flight path. An image distortion can be seen at the right-hand side, where the landing spot sign appears twice, while in reality, only one circle was visible.}\relax }}{42}}
\newlabel{fig:mapexp}{{4.7}{42}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.7}Experiment -- Triggered Landing}{42}}
\newlabel{sec:triggered}{{4.7}{42}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.8}Experiment -- Determining the Frequency}{43}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.9}Experiment -- Comparing different possible maps}{43}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Map evaluation procedure on synthetic data}}{44}}
\newlabel{tab:mapeval}{{4.3}{44}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces { Image with the lowest loss value; \emph  {Right}: Image with the highest loss value}\relax }}{44}}
\newlabel{fig:minmaximg}{{4.8}{44}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussion}{45}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:discussion}{{5}{45}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}General Discussion}{46}}
\newlabel{sec:generaldiscussion}{{5.1}{46}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces { Exemplifying the reality gap. \emph  {Top left}: image patch generated using the synthetic data generation tool. \emph  {Top right}: image patch taken with the MAV's camera after printing the patch. \emph  {Below left}: Texton image of the synthetic image. In the image, the colors indicate the closest texton (dictionary size: 20 textons) at the respective position. \emph  {Below right}: Texton image of the real image. }\relax }}{49}}
\newlabel{fig:realitygap}{{5.1}{49}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{50}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{6}{50}}
