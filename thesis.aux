\relax 
\abx@aux@sortscheme{nty}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{english}}
\abx@aux@cite{grzonka2009towards}
\abx@aux@cite{bachrach2009autonomous}
\abx@aux@cite{blosch2010vision}
\abx@aux@cite{angeli20062d}
\abx@aux@cite{ahrens2009vision}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:introduction}{{1}{2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces { The figure illustrates the proposed system from a high-level perspective. A feature vector---the texton histogram---is extracted from the current camera image of the UAV. The feature vector is forwarded to a machine learning model that uses a $k$-Nearest Neighbors algorithm to output $x,y$-position estimates. These estimates are passed to a particle filter, which filters position estimates over time and outputs a final position estimate (red point). The expected loss shows regions in the map where a lower localization accuracy is expected. The average expected loss can be used as ``fitness value'' of a given map.}\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:highleveloverview}{{1.1}{3}}
\abx@aux@cite{varma2005statistical}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem Statement and Research Questions}{4}}
\newlabel{sec:researchquestions}{{1.1}{4}}
\abx@aux@cite{brisset2006paparazzi}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contributions}{5}}
\newlabel{sec:contributions}{{1.2}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis Outline}{6}}
\newlabel{sec:outline}{{1.3}{6}}
\abx@aux@cite{fox1999monte}
\abx@aux@cite{engelson1992error}
\abx@aux@cite{kato1999marker}
\abx@aux@cite{garrido2014automatic}
\abx@aux@cite{eberli2011vision}
\abx@aux@cite{bebop2015}
\abx@aux@cite{aruco2014}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:relatedwork}{{2}{7}}
\abx@aux@cite{hornecker2005using}
\abx@aux@cite{albasiouny2015mean}
\abx@aux@cite{chu2013halftone}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Vision-based Localization Methods}{8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Fiducial Markers}{8}}
\newlabel{sec:fiducialmarkers}{{2.1.1}{8}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces { Examples of fiducial markers of the ArUco library.}\relax }}{8}}
\newlabel{fig:aruco}{{2.1}{8}}
\abx@aux@cite{se2002global}
\abx@aux@cite{lowe1999object}
\abx@aux@cite{kendall2015posenet}
\abx@aux@cite{achtelik2011onboard}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Homography Determination \& Keypoint Matching}{9}}
\newlabel{sec:keypointmatching}{{2.1.2}{9}}
\abx@aux@cite{lecun1998gradient}
\abx@aux@cite{dosovitskiy2014discriminative}
\abx@aux@cite{collobert2011torch7}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces {Perspective transformation between keypoints of the current image (left) and the reference or map image (right).}\relax }}{10}}
\newlabel{fig:sift}{{2.2}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Convolutional Neural Networks}{10}}
\abx@aux@cite{ruffier2003bio}
\abx@aux@cite{chao2013survey}
\abx@aux@cite{mcguire2016local}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Optical Flow}{11}}
\newlabel{sec:opticalflow}{{2.1.4}{11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Texton-based Methods}{11}}
\newlabel{sec:textonbasedapproaches}{{2.2}{11}}
\abx@aux@cite{de2009design}
\abx@aux@cite{de2012appearance}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods}{13}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methods}{{3}{13}}
\@writefile{loa}{\defcounter {refsection}{0}\relax }\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces High-level texton framework\relax }}{13}}
\newlabel{alg:trexton_run}{{1}{13}}
\abx@aux@cite{bebop}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Hardware and Software}{14}}
\newlabel{sec:hardware}{{3.1}{14}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces { Comparison of an unmodified Parrot AR.Drone.2.0 (left) and a modified version (right). The modified one was equipped with an Odroid XU-4 single board computer, a Logitech C525 HD camera, a WiFi module, and a USB connection between the Odroid board and the AR.Drone.2.0 flight controller.}\relax }}{14}}
\newlabel{fig:comparison}{{3.1}{14}}
\abx@aux@cite{paparazzi}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces { The ground control station of the Paparazzi software. It displays information about the status of the UAV and provides functions for controlling the vehicle (from PaparazziUAV wiki \cite {paparazzi}).}\relax }}{16}}
\newlabel{fig:gcs}{{3.2}{16}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Preliminary Dataset Generation}{16}}
\newlabel{sec:mapping}{{3.2}{16}}
\abx@aux@cite{ice}
\abx@aux@cite{hugin}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces {Training dataset generation if the motion tracking system is used. The texton histograms of the camera images during flight are extracted and aligned with the highly accurate position estimates of the motion tracking system. The result is a high-quality training set of texton histograms and corresponding $x,y$-positions.}\relax }}{17}}
\newlabel{fig:overviewn}{{3.3}{17}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces { The figure illustrates the training set generation when applying the homography-based approach. Images from an initial flight are stitched together to create an orthomap. The same images are used to detect and describe their keypoints using \textsc  {Sift}, followed by finding a homography between the keypoints of the flight images and the orthomap to obtain $x, y$-coordinates per image. The training set is created by extracting texton histograms from the images. }\relax }}{19}}
\newlabel{fig:overview_sift}{{3.4}{19}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Machine Learning-based Approach and Filtering}{19}}
\newlabel{sec:textons}{{3.3}{19}}
\abx@aux@cite{varma2003texture}
\abx@aux@cite{kohonen1990self}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces { This figure shows the created orthomap of a texture-rich floor. It is stitched together using 100 single images and represents a real world area of approximately $8\times 8$ meters. Image distortions, non-mapped areas, and slightly skewed seams at several points are visible.}\relax }}{20}}
\newlabel{fig:orthomap}{{3.5}{20}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Texton Dictionary Generation}{20}}
\newlabel{sec:text-dict-gener}{{3.3.1}{20}}
\abx@aux@cite{guyon2006introduction}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces { The figures shows a dictionary consisting of 20 grayscale textons ($w \times h = 6 \times 6$ pixels).}\relax }}{21}}
\newlabel{fig:dictionary}{{3.6}{21}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Histogram Extraction}{21}}
\newlabel{sec:histogramextract}{{3.3.2}{21}}
\abx@aux@cite{de2012sub}
\abx@aux@cite{kordos2010we}
\abx@aux@cite{knn}
\abx@aux@cite{bhatia2010survey}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}$k$-Nearest Neighbors ($k$-NN) algorithm}{22}}
\newlabel{sec:knn}{{3.3.3}{22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Training Set based on Homography-finding Method}{23}}
\newlabel{sec:traininghomo}{{3.3.4}{23}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces { The created map that was stitched together using 445 images. A non-mapped area in the middle of the map can be seen, which is a result of the set flight path. An image distortion can be seen at the right-hand side, where the landing spot sign appears twice, while in reality, only one circle was visible.}\relax }}{23}}
\newlabel{fig:mapexp}{{3.7}{23}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Experiment -- Triggered Landing}{23}}
\newlabel{sec:triggered}{{3.4}{23}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Triggered landings}}{24}}
\newlabel{tab:targetlanding}{{3.1}{24}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiment -- Determining the Frequency}{24}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.6}Experiment -- Comparing different possible maps}{24}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Map evaluation procedure on synthetic data}}{25}}
\newlabel{tab:mapeval}{{3.2}{25}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces { Image with the lowest loss value; \emph  {Right}: Image with the highest loss value}\relax }}{25}}
\newlabel{fig:minmaximg}{{3.8}{25}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Discussion}{26}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:discussion}{{4}{26}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}General Discussion}{27}}
\newlabel{sec:generaldiscussion}{{4.1}{27}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces { Exemplifying the reality gap. \emph  {Top left}: image patch generated using draug. \emph  {Top right}: image patch taken with the MAV's camera after printing the patch. \emph  {Below left}: texton image of the synthetic image. \emph  {Below right}: Texton image of the real image. The texton images shows that corresponding regions get classified into different textons, resulting in different histograms. This makes the transfer from the synthetic data to the real world difficult.}\relax }}{29}}
\newlabel{fig:realitygap}{{4.1}{29}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{31}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{5}{31}}
